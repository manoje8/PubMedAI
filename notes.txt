Retrieval-Augmented Generation:
    Retrieval-Augmented Generation (RAG) systems enhance large language models (LLMs) by integrating external knowledge
    sources, enabling more accurate and contextually relevant responses tailored to user needs.

LightRAG:
    LightRAG, which incorporates graph structures into text indexing and retrieval processes. This innovative framework
    employs a dual-level retrieval system that enhances comprehensive information retrieval from both low-level and
    high-level knowledge discovery. Additionally, the integration of graph structures with vector representations
    facilitates efficient retrieval of related entities and their relationships, significantly improving response times
    while maintaining contextual relevance.

Tokenization:
    It's breaking down text into smaller units, known as tokens, which can be words, subwords, or characters.
Efficient tokenization is crucial for the performance of language models, making it an essential step in
various NLP tasks such as text generation, translation, and summarization.


Context Engineering transforms raw input into  meaningful structure
Playbooks provide evidence-based pathways relevant to the case
Prompt Engineering optimizes how we ask the AI to analyze the case